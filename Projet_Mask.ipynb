{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Projet_Mask.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "history_visible": true,
      "mount_file_id": "1EX_eKMHP6zjFUp_c3aD7Q3aDwQNZOnHi",
      "authorship_tag": "ABX9TyM/MK1VaWZ6tPe/4NTK+5DZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bruaba/mask_detection/blob/main/Projet_Mask.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Un-gY1PjvoK8"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Sun Nov 29 18:40:11 2020\n",
        "\n",
        "@author: cheikh\n",
        "\"\"\"\n",
        "#libraries\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import random as rand\n",
        "import keras\n",
        "import tensorflow_addons as tfa\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')   # Suppress Matplotlib warnings\n",
        "from PIL import Image\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.layers import AveragePooling2D\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "#from keras_radam import RAdam\n",
        "from imutils import paths\n",
        "from bs4 import BeautifulSoup"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JoSSVpfMzbA"
      },
      "source": [
        "def load_image_into_numpy_array(path):\n",
        "    \"\"\"Load an image from file into a numpy array.\n",
        "\n",
        "    Puts image into numpy array to feed into tensorflow graph.\n",
        "    Note that by convention we put it into a numpy array with shape\n",
        "    (height, width, channels), where channels=3 for RGB.\n",
        "\n",
        "    Args:\n",
        "      path: the file path to the image\n",
        "\n",
        "    Returns:\n",
        "      uint8 numpy array with shape (img_height, img_width, 3)\n",
        "    \"\"\"\n",
        "    return np.array(Image.open(path))"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsDZaMY-wlPG"
      },
      "source": [
        "def generate_box(obj):  \n",
        "    xmin = int(float(obj.find('xmin').text))\n",
        "    ymin = int(float(obj.find('ymin').text))\n",
        "    xmax = int(float(obj.find('xmax').text))\n",
        "    ymax = int(float(obj.find('ymax').text))\n",
        "    \n",
        "    return [xmin, ymin, xmax, ymax]\n",
        "\n",
        "#This function will give label assciated with each label and convert them to numbers\n",
        "def generate_label(obj):\n",
        "    if obj.find('name').text == \"with_mask\":\n",
        "        return 1\n",
        "    elif obj.find('name').text == \"mask_weared_incorrect\":\n",
        "        return 2\n",
        "#    elif obj.find('name').text == \"without_mask\":\n",
        "#        return 3\n",
        "    return 0\n",
        "\n",
        "#Using in this main function we parse the annotations file and get the objects out from them\n",
        "# Also we use the above two functions here \n",
        "def generate_target(image_id, file): \n",
        "    with open(file) as f:\n",
        "        data = f.read()\n",
        "        soup = BeautifulSoup(data, 'xml')\n",
        "        objects = soup.find_all('object')\n",
        "\n",
        "        num_objs = len(objects)\n",
        "\n",
        "        boxes = []\n",
        "        labels = []\n",
        "        for i in objects:\n",
        "            boxes.append(generate_box(i))\n",
        "            labels.append(generate_label(i))\n",
        "            \n",
        "        boxes=np.array(boxes)\n",
        "        labels=np.array(labels)\n",
        "\n",
        "        img_id = np.array(image_id)\n",
        "    # Annotation is in dictionary format\n",
        "        target = {}\n",
        "        target[\"boxes\"] = boxes\n",
        "        target[\"labels\"] = labels\n",
        "        \n",
        "        return (target,num_objs)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yT5qDo6VJWGM"
      },
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/MyDrive/Colab Notebooks\")\n",
        "#!ls"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Vn5dLPrwqwx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d6512d7-a1cb-43f2-9fcd-1d7e1b8019b1"
      },
      "source": [
        "\n",
        "\n",
        "imgs = list(sorted(os.listdir(\"MaskTrainDataset/JPEGImages/\")))\n",
        "labels = list(sorted(os.listdir(\"MaskTrainDataset/Annotations/\")))\n",
        "#nombre d'images et de labels\n",
        "print(len(imgs))\n",
        "print(len(labels))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2655\n",
            "2655\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dm5bJc3T475"
      },
      "source": [
        "# Here we use the above functions and save results in lists\n",
        "targets=[]#store coordinates\n",
        "numobjs=[]#stores number of faces in each image\n",
        "#run the loop for number of images we have\n",
        "\n",
        "i=0\n",
        "for dirname, _, filenames in os.walk('MaskTrainDataset/Annotations/'):\n",
        "    for filename in filenames:\n",
        "        target, numobj = generate_target(i, os.path.join(dirname, filename))\n",
        "        targets.append(target)\n",
        "        numobjs.append(numobj)\n",
        "        i+=1\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4f45ziC0--o"
      },
      "source": [
        "i=0\n",
        "face_images=[]\n",
        "face_labels=[]\n",
        "\n",
        "\n",
        "for dirname, _, filenames in os.walk('MaskTrainDataset/JPEGImages/'):\n",
        "    for filename in filenames:\n",
        "        img_path = os.path.join(dirname, filename)\n",
        "        img = cv2.imread(img_path)\n",
        "        for j in range(numobjs[i]):\n",
        "            locs = (targets[i]['boxes'][j])\n",
        "            img1 = img[int(locs[1]):int(locs[3]), int(locs[0]):int(locs[2])]       \n",
        "            try:\n",
        "                img1 = cv2.resize(img1, (224, 224))\n",
        "                img1 = img_to_array(img1)\n",
        "                img1 = preprocess_input(img1)\n",
        "                face_images.append(img1)\n",
        "                face_labels.append(targets[i]['labels'][j])\n",
        "            except cv2.error:\n",
        "                continue\n",
        "            \n",
        "        i+=1\n",
        "face_images= np.array(face_images, dtype=\"float32\")\n",
        "face_labels = np.array(face_labels)\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIoNc1K311Fw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e793347-84f5-40ac-f6e3-5109362ded5e"
      },
      "source": [
        "\n",
        "\n",
        "imgs = list(sorted(os.listdir(\"VALIDATION/IMAGES/\")))\n",
        "labels = list(sorted(os.listdir(\"VALIDATION/ANNOTATIONS/\")))\n",
        "#nombre d'images et de labels\n",
        "print(len(imgs))\n",
        "print(len(labels))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "853\n",
            "853\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7m6883fl1lPS"
      },
      "source": [
        "# Here we use the above functions and save results in lists\n",
        "targets=[]#store coordinates\n",
        "numobjs=[]#stores number of faces in each image\n",
        "#run the loop for number of images we have\n",
        "\n",
        "i=0\n",
        "for dirname, _, filenames in os.walk('VALIDATION/ANNOTATIONS/'):\n",
        "    for filename in filenames:\n",
        "        target, numobj = generate_target(i, os.path.join(dirname, filename))\n",
        "        targets.append(target)\n",
        "        numobjs.append(numobj)\n",
        "        i+=1\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2A1ou6Cyr6v"
      },
      "source": [
        "i=0\n",
        "kaggle_images=[]\n",
        "kaggle_labels=[]\n",
        "\n",
        "\n",
        "for dirname, _, filenames in os.walk('VALIDATION/IMAGES/'):\n",
        "    for filename in filenames:\n",
        "        img_path = os.path.join(dirname, filename)\n",
        "        img = cv2.imread(img_path)\n",
        "        for j in range(numobjs[i]):\n",
        "            locs = (targets[i]['boxes'][j])\n",
        "            img1 = img[int(locs[1]):int(locs[3]), int(locs[0]):int(locs[2])]       \n",
        "            try:\n",
        "                img1 = cv2.resize(img1, (224, 224))\n",
        "                img1 = img_to_array(img1)\n",
        "                img1 = preprocess_input(img1)\n",
        "                kaggle_images.append(img1)\n",
        "                kaggle_labels.append(targets[i]['labels'][j])\n",
        "            except cv2.error:\n",
        "                continue\n",
        "            \n",
        "        i+=1\n",
        "kaggle_images= np.array(kaggle_images, dtype=\"float32\")\n",
        "kaggle_labels = np.array(kaggle_labels)\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnFYjyMk01Og",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e080cdb-edda-41bf-ba3d-0f382053651d"
      },
      "source": [
        "#Kaggle\n",
        "print(len(kaggle_labels))\n",
        "print(len(kaggle_images))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3778\n",
            "3778\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I49lrVD_5GGR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "134290ff-f917-42c4-e995-26b5a2c4ec9d"
      },
      "source": [
        "\n",
        "print(len(face_labels))\n",
        "print(len(face_images))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5773\n",
            "5773\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EC-lq2K2GLL"
      },
      "source": [
        "unique, counts = np.unique(kaggle_labels, return_counts=True)\n",
        "print(dict(zip(unique, counts)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfQkzLrKUIxa"
      },
      "source": [
        "unique, counts = np.unique(face_labels, return_counts=True)\n",
        "print(dict(zip(unique, counts)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvKGgPhYUM9q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bcfdd17-e7a1-40bd-8ee3-4b80d15fa38e"
      },
      "source": [
        "#Encode the labels in one hot encode form\n",
        "\n",
        "#c'est pour transformer les données non numerique en numerique\n",
        "#ici les labels\n",
        "#https://stackoverrun.com/fr/q/12291556\n",
        "\n",
        "lb = LabelEncoder()\n",
        "train_labels = lb.fit_transform(face_labels)\n",
        "train_labels = to_categorical(train_labels)\n",
        "print(train_labels)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " ...\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqzH6WHr2o3X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f54da6e9-865e-45f9-989f-935a47317f77"
      },
      "source": [
        "#Encode the labels in one hot encode form\n",
        "\n",
        "#c'est pour transformer les données non numerique en numerique\n",
        "#ici les labels\n",
        "#https://stackoverrun.com/fr/q/12291556\n",
        "\n",
        "lb = LabelEncoder()\n",
        "kag_labels = lb.fit_transform(kaggle_labels)\n",
        "kag_labels = to_categorical(kag_labels)\n",
        "print(kag_labels)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " ...\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_7eBuTh9_oY"
      },
      "source": [
        "del lb, i, labels, numobjs, imgs, targets, face_labels, kaggle_labels"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7Bigd_QUcW4"
      },
      "source": [
        "#divide data into training and testing sets\n",
        "(trainX, z, trainY, w) = train_test_split(face_images, train_labels,\n",
        "    test_size=0.20, stratify=train_labels, random_state=42)\n",
        "\n",
        "\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcPXFq5A9RB5"
      },
      "source": [
        "#Free some space.I did this tep as the notebook was running out of space while training\n",
        "del face_images,train_labels, z, w"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWw-BsnhtX5C"
      },
      "source": [
        "(x, testX, y, testY) = train_test_split(kaggle_images, kag_labels,\n",
        "    test_size=0.20, stratify=kag_labels, random_state=42)\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Zp82ReD4xLv"
      },
      "source": [
        "#Free some space.I did this tep as the notebook was running out of space while training\n",
        "del kaggle_images, kag_labels, x, y"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8HVBynk5Axt"
      },
      "source": [
        "# construct the training image generator for data augmentation\n",
        "\"\"\"\n",
        "La classe ImageDataGenerator garantit que le modèle reçoit de nouvelles variations des images à chaque époque. \n",
        "Mais il ne renvoie que les images transformées et ne les ajoute pas au corpus original d'images. \n",
        "Si c'était effectivement le cas, alors le modèle verrait les images originales plusieurs fois, ce qui sur-adapterait certainement notre modèle.\n",
        "\n",
        "Un autre avantage d'ImageDataGenerator est qu'il nécessite une moindre utilisation de la mémoire. \n",
        "En effet, sans utiliser cette classe, nous chargeons toutes les images en même temps. Mais en l'utilisant, nous chargeons les images par lots, ce qui économise beaucoup de mémoire.\n",
        "\"\"\"\n",
        "#https://www.analyticsvidhya.com/blog/2020/08/image-augmentation-on-the-fly-using-keras-imagedatagenerator/\n",
        "aug = ImageDataGenerator(\n",
        "\trotation_range=25,\n",
        "\tzoom_range=0.15,\n",
        "\twidth_shift_range=0.2,\n",
        "\theight_shift_range=0.2,\n",
        "\tshear_range=0.15,\n",
        "  vertical_flip = True,\n",
        "\tfill_mode=\"nearest\")"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYCan6QkUSfv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6316744d-e847-48c8-d32b-adc556413a69"
      },
      "source": [
        "#https://deeplylearning.fr/cours-theoriques-deep-learning/transfer-learning/\n",
        "\n",
        "\n",
        "# load the MobileNetV2 network, ensuring the head FC layer sets are\n",
        "# left off\n",
        "#Notamment, MobileNetV2 + SSDLite est 20 fois plus efficace et 10 fois plus petit, tout en surpassant YOLOv2 sur l'ensemble de données COCO.\n",
        "#https://towardsdatascience.com/review-mobilenetv2-light-weight-model-image-classification-8febb490e61c\n",
        "\n",
        "#https://keras.io/api/applications/mobilenet/\n",
        "\n",
        "baseModel = MobileNetV2(weights=\"imagenet\", include_top=False,\n",
        "                        input_shape=(224, 224, 3))\n",
        "\n",
        "# construct the head of the model that will be placed on top of the\n",
        "# the base model\n",
        "headModel = baseModel.output\n",
        "#https://www.machinecurve.com/index.php/2020/01/30/what-are-max-pooling-average-pooling-global-max-pooling-and-global-average-pooling/\n",
        "headModel = AveragePooling2D(pool_size=(7, 7))(headModel)\n",
        "#appaltir\n",
        "headModel = Flatten(name=\"flatten\")(headModel)\n",
        "\n",
        "\n",
        "headModel = Dense(256, activation=\"relu\")(headModel)\n",
        "# headModel = Dense(128, activation=\"relu\")(headModel)\n",
        "# headModel = Dense(512, activation=\"sigmoid\")(headModel)\n",
        "# supprimer certain noeud\n",
        "# headModel = Dropout(0.5)(headModel)\n",
        "headModel = Dropout(0.25)(headModel)\n",
        "headModel = Dense(3, activation=\"softmax\")(headModel)\n",
        "\n",
        "\n",
        "# place the head FC model on top of the base model (this will become\n",
        "# the actual model we will train)\n",
        "model = Model(inputs=baseModel.input, outputs=headModel)\n",
        "print(model.summary())\n",
        "\n",
        "# loop over all layers in the base model and freeze them so they will\n",
        "# *not* be updated during the first training process\n",
        "for layer in baseModel.layers:\n",
        "\tlayer.trainable = False"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Conv1 (Conv2D)                  (None, 112, 112, 32) 864         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bn_Conv1 (BatchNormalization)   (None, 112, 112, 32) 128         Conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "Conv1_relu (ReLU)               (None, 112, 112, 32) 0           bn_Conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "expanded_conv_depthwise (Depthw (None, 112, 112, 32) 288         Conv1_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "expanded_conv_depthwise_BN (Bat (None, 112, 112, 32) 128         expanded_conv_depthwise[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "expanded_conv_depthwise_relu (R (None, 112, 112, 32) 0           expanded_conv_depthwise_BN[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "expanded_conv_project (Conv2D)  (None, 112, 112, 16) 512         expanded_conv_depthwise_relu[0][0\n",
            "__________________________________________________________________________________________________\n",
            "expanded_conv_project_BN (Batch (None, 112, 112, 16) 64          expanded_conv_project[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block_1_expand (Conv2D)         (None, 112, 112, 96) 1536        expanded_conv_project_BN[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "block_1_expand_BN (BatchNormali (None, 112, 112, 96) 384         block_1_expand[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block_1_expand_relu (ReLU)      (None, 112, 112, 96) 0           block_1_expand_BN[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_1_pad (ZeroPadding2D)     (None, 113, 113, 96) 0           block_1_expand_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_1_depthwise (DepthwiseCon (None, 56, 56, 96)   864         block_1_pad[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block_1_depthwise_BN (BatchNorm (None, 56, 56, 96)   384         block_1_depthwise[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_1_depthwise_relu (ReLU)   (None, 56, 56, 96)   0           block_1_depthwise_BN[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_1_project (Conv2D)        (None, 56, 56, 24)   2304        block_1_depthwise_relu[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block_1_project_BN (BatchNormal (None, 56, 56, 24)   96          block_1_project[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_2_expand (Conv2D)         (None, 56, 56, 144)  3456        block_1_project_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_2_expand_BN (BatchNormali (None, 56, 56, 144)  576         block_2_expand[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block_2_expand_relu (ReLU)      (None, 56, 56, 144)  0           block_2_expand_BN[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_2_depthwise (DepthwiseCon (None, 56, 56, 144)  1296        block_2_expand_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_2_depthwise_BN (BatchNorm (None, 56, 56, 144)  576         block_2_depthwise[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_2_depthwise_relu (ReLU)   (None, 56, 56, 144)  0           block_2_depthwise_BN[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_2_project (Conv2D)        (None, 56, 56, 24)   3456        block_2_depthwise_relu[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block_2_project_BN (BatchNormal (None, 56, 56, 24)   96          block_2_project[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_2_add (Add)               (None, 56, 56, 24)   0           block_1_project_BN[0][0]         \n",
            "                                                                 block_2_project_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_3_expand (Conv2D)         (None, 56, 56, 144)  3456        block_2_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block_3_expand_BN (BatchNormali (None, 56, 56, 144)  576         block_3_expand[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block_3_expand_relu (ReLU)      (None, 56, 56, 144)  0           block_3_expand_BN[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_3_pad (ZeroPadding2D)     (None, 57, 57, 144)  0           block_3_expand_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_3_depthwise (DepthwiseCon (None, 28, 28, 144)  1296        block_3_pad[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block_3_depthwise_BN (BatchNorm (None, 28, 28, 144)  576         block_3_depthwise[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_3_depthwise_relu (ReLU)   (None, 28, 28, 144)  0           block_3_depthwise_BN[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_3_project (Conv2D)        (None, 28, 28, 32)   4608        block_3_depthwise_relu[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block_3_project_BN (BatchNormal (None, 28, 28, 32)   128         block_3_project[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_4_expand (Conv2D)         (None, 28, 28, 192)  6144        block_3_project_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_4_expand_BN (BatchNormali (None, 28, 28, 192)  768         block_4_expand[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block_4_expand_relu (ReLU)      (None, 28, 28, 192)  0           block_4_expand_BN[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_4_depthwise (DepthwiseCon (None, 28, 28, 192)  1728        block_4_expand_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_4_depthwise_BN (BatchNorm (None, 28, 28, 192)  768         block_4_depthwise[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_4_depthwise_relu (ReLU)   (None, 28, 28, 192)  0           block_4_depthwise_BN[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_4_project (Conv2D)        (None, 28, 28, 32)   6144        block_4_depthwise_relu[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block_4_project_BN (BatchNormal (None, 28, 28, 32)   128         block_4_project[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_4_add (Add)               (None, 28, 28, 32)   0           block_3_project_BN[0][0]         \n",
            "                                                                 block_4_project_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_5_expand (Conv2D)         (None, 28, 28, 192)  6144        block_4_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block_5_expand_BN (BatchNormali (None, 28, 28, 192)  768         block_5_expand[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block_5_expand_relu (ReLU)      (None, 28, 28, 192)  0           block_5_expand_BN[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_5_depthwise (DepthwiseCon (None, 28, 28, 192)  1728        block_5_expand_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_5_depthwise_BN (BatchNorm (None, 28, 28, 192)  768         block_5_depthwise[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_5_depthwise_relu (ReLU)   (None, 28, 28, 192)  0           block_5_depthwise_BN[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_5_project (Conv2D)        (None, 28, 28, 32)   6144        block_5_depthwise_relu[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block_5_project_BN (BatchNormal (None, 28, 28, 32)   128         block_5_project[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_5_add (Add)               (None, 28, 28, 32)   0           block_4_add[0][0]                \n",
            "                                                                 block_5_project_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_6_expand (Conv2D)         (None, 28, 28, 192)  6144        block_5_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block_6_expand_BN (BatchNormali (None, 28, 28, 192)  768         block_6_expand[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block_6_expand_relu (ReLU)      (None, 28, 28, 192)  0           block_6_expand_BN[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_6_pad (ZeroPadding2D)     (None, 29, 29, 192)  0           block_6_expand_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_6_depthwise (DepthwiseCon (None, 14, 14, 192)  1728        block_6_pad[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block_6_depthwise_BN (BatchNorm (None, 14, 14, 192)  768         block_6_depthwise[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_6_depthwise_relu (ReLU)   (None, 14, 14, 192)  0           block_6_depthwise_BN[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_6_project (Conv2D)        (None, 14, 14, 64)   12288       block_6_depthwise_relu[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block_6_project_BN (BatchNormal (None, 14, 14, 64)   256         block_6_project[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_7_expand (Conv2D)         (None, 14, 14, 384)  24576       block_6_project_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_7_expand_BN (BatchNormali (None, 14, 14, 384)  1536        block_7_expand[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block_7_expand_relu (ReLU)      (None, 14, 14, 384)  0           block_7_expand_BN[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_7_depthwise (DepthwiseCon (None, 14, 14, 384)  3456        block_7_expand_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_7_depthwise_BN (BatchNorm (None, 14, 14, 384)  1536        block_7_depthwise[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_7_depthwise_relu (ReLU)   (None, 14, 14, 384)  0           block_7_depthwise_BN[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_7_project (Conv2D)        (None, 14, 14, 64)   24576       block_7_depthwise_relu[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block_7_project_BN (BatchNormal (None, 14, 14, 64)   256         block_7_project[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_7_add (Add)               (None, 14, 14, 64)   0           block_6_project_BN[0][0]         \n",
            "                                                                 block_7_project_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_8_expand (Conv2D)         (None, 14, 14, 384)  24576       block_7_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block_8_expand_BN (BatchNormali (None, 14, 14, 384)  1536        block_8_expand[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block_8_expand_relu (ReLU)      (None, 14, 14, 384)  0           block_8_expand_BN[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_8_depthwise (DepthwiseCon (None, 14, 14, 384)  3456        block_8_expand_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_8_depthwise_BN (BatchNorm (None, 14, 14, 384)  1536        block_8_depthwise[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_8_depthwise_relu (ReLU)   (None, 14, 14, 384)  0           block_8_depthwise_BN[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_8_project (Conv2D)        (None, 14, 14, 64)   24576       block_8_depthwise_relu[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block_8_project_BN (BatchNormal (None, 14, 14, 64)   256         block_8_project[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_8_add (Add)               (None, 14, 14, 64)   0           block_7_add[0][0]                \n",
            "                                                                 block_8_project_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_9_expand (Conv2D)         (None, 14, 14, 384)  24576       block_8_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block_9_expand_BN (BatchNormali (None, 14, 14, 384)  1536        block_9_expand[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block_9_expand_relu (ReLU)      (None, 14, 14, 384)  0           block_9_expand_BN[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_9_depthwise (DepthwiseCon (None, 14, 14, 384)  3456        block_9_expand_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_9_depthwise_BN (BatchNorm (None, 14, 14, 384)  1536        block_9_depthwise[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_9_depthwise_relu (ReLU)   (None, 14, 14, 384)  0           block_9_depthwise_BN[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_9_project (Conv2D)        (None, 14, 14, 64)   24576       block_9_depthwise_relu[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block_9_project_BN (BatchNormal (None, 14, 14, 64)   256         block_9_project[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_9_add (Add)               (None, 14, 14, 64)   0           block_8_add[0][0]                \n",
            "                                                                 block_9_project_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_10_expand (Conv2D)        (None, 14, 14, 384)  24576       block_9_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block_10_expand_BN (BatchNormal (None, 14, 14, 384)  1536        block_10_expand[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_10_expand_relu (ReLU)     (None, 14, 14, 384)  0           block_10_expand_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_10_depthwise (DepthwiseCo (None, 14, 14, 384)  3456        block_10_expand_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_10_depthwise_BN (BatchNor (None, 14, 14, 384)  1536        block_10_depthwise[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_10_depthwise_relu (ReLU)  (None, 14, 14, 384)  0           block_10_depthwise_BN[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block_10_project (Conv2D)       (None, 14, 14, 96)   36864       block_10_depthwise_relu[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block_10_project_BN (BatchNorma (None, 14, 14, 96)   384         block_10_project[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_11_expand (Conv2D)        (None, 14, 14, 576)  55296       block_10_project_BN[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_11_expand_BN (BatchNormal (None, 14, 14, 576)  2304        block_11_expand[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_11_expand_relu (ReLU)     (None, 14, 14, 576)  0           block_11_expand_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_11_depthwise (DepthwiseCo (None, 14, 14, 576)  5184        block_11_expand_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_11_depthwise_BN (BatchNor (None, 14, 14, 576)  2304        block_11_depthwise[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_11_depthwise_relu (ReLU)  (None, 14, 14, 576)  0           block_11_depthwise_BN[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block_11_project (Conv2D)       (None, 14, 14, 96)   55296       block_11_depthwise_relu[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block_11_project_BN (BatchNorma (None, 14, 14, 96)   384         block_11_project[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_11_add (Add)              (None, 14, 14, 96)   0           block_10_project_BN[0][0]        \n",
            "                                                                 block_11_project_BN[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_12_expand (Conv2D)        (None, 14, 14, 576)  55296       block_11_add[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block_12_expand_BN (BatchNormal (None, 14, 14, 576)  2304        block_12_expand[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_12_expand_relu (ReLU)     (None, 14, 14, 576)  0           block_12_expand_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_12_depthwise (DepthwiseCo (None, 14, 14, 576)  5184        block_12_expand_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_12_depthwise_BN (BatchNor (None, 14, 14, 576)  2304        block_12_depthwise[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_12_depthwise_relu (ReLU)  (None, 14, 14, 576)  0           block_12_depthwise_BN[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block_12_project (Conv2D)       (None, 14, 14, 96)   55296       block_12_depthwise_relu[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block_12_project_BN (BatchNorma (None, 14, 14, 96)   384         block_12_project[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_12_add (Add)              (None, 14, 14, 96)   0           block_11_add[0][0]               \n",
            "                                                                 block_12_project_BN[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_13_expand (Conv2D)        (None, 14, 14, 576)  55296       block_12_add[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block_13_expand_BN (BatchNormal (None, 14, 14, 576)  2304        block_13_expand[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_13_expand_relu (ReLU)     (None, 14, 14, 576)  0           block_13_expand_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_13_pad (ZeroPadding2D)    (None, 15, 15, 576)  0           block_13_expand_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_13_depthwise (DepthwiseCo (None, 7, 7, 576)    5184        block_13_pad[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block_13_depthwise_BN (BatchNor (None, 7, 7, 576)    2304        block_13_depthwise[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_13_depthwise_relu (ReLU)  (None, 7, 7, 576)    0           block_13_depthwise_BN[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block_13_project (Conv2D)       (None, 7, 7, 160)    92160       block_13_depthwise_relu[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block_13_project_BN (BatchNorma (None, 7, 7, 160)    640         block_13_project[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_14_expand (Conv2D)        (None, 7, 7, 960)    153600      block_13_project_BN[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_14_expand_BN (BatchNormal (None, 7, 7, 960)    3840        block_14_expand[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_14_expand_relu (ReLU)     (None, 7, 7, 960)    0           block_14_expand_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_14_depthwise (DepthwiseCo (None, 7, 7, 960)    8640        block_14_expand_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_14_depthwise_BN (BatchNor (None, 7, 7, 960)    3840        block_14_depthwise[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_14_depthwise_relu (ReLU)  (None, 7, 7, 960)    0           block_14_depthwise_BN[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block_14_project (Conv2D)       (None, 7, 7, 160)    153600      block_14_depthwise_relu[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block_14_project_BN (BatchNorma (None, 7, 7, 160)    640         block_14_project[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_14_add (Add)              (None, 7, 7, 160)    0           block_13_project_BN[0][0]        \n",
            "                                                                 block_14_project_BN[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_15_expand (Conv2D)        (None, 7, 7, 960)    153600      block_14_add[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block_15_expand_BN (BatchNormal (None, 7, 7, 960)    3840        block_15_expand[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_15_expand_relu (ReLU)     (None, 7, 7, 960)    0           block_15_expand_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_15_depthwise (DepthwiseCo (None, 7, 7, 960)    8640        block_15_expand_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_15_depthwise_BN (BatchNor (None, 7, 7, 960)    3840        block_15_depthwise[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_15_depthwise_relu (ReLU)  (None, 7, 7, 960)    0           block_15_depthwise_BN[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block_15_project (Conv2D)       (None, 7, 7, 160)    153600      block_15_depthwise_relu[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block_15_project_BN (BatchNorma (None, 7, 7, 160)    640         block_15_project[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_15_add (Add)              (None, 7, 7, 160)    0           block_14_add[0][0]               \n",
            "                                                                 block_15_project_BN[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_16_expand (Conv2D)        (None, 7, 7, 960)    153600      block_15_add[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block_16_expand_BN (BatchNormal (None, 7, 7, 960)    3840        block_16_expand[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_16_expand_relu (ReLU)     (None, 7, 7, 960)    0           block_16_expand_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_16_depthwise (DepthwiseCo (None, 7, 7, 960)    8640        block_16_expand_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_16_depthwise_BN (BatchNor (None, 7, 7, 960)    3840        block_16_depthwise[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_16_depthwise_relu (ReLU)  (None, 7, 7, 960)    0           block_16_depthwise_BN[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block_16_project (Conv2D)       (None, 7, 7, 320)    307200      block_16_depthwise_relu[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block_16_project_BN (BatchNorma (None, 7, 7, 320)    1280        block_16_project[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "Conv_1 (Conv2D)                 (None, 7, 7, 1280)   409600      block_16_project_BN[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Conv_1_bn (BatchNormalization)  (None, 7, 7, 1280)   5120        Conv_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "out_relu (ReLU)                 (None, 7, 7, 1280)   0           Conv_1_bn[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 1, 1, 1280)   0           out_relu[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 1280)         0           average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 128)          163968      flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 128)          0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 3)            387         dropout_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 2,422,339\n",
            "Trainable params: 2,388,227\n",
            "Non-trainable params: 34,112\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATU92ddD48B2"
      },
      "source": [
        "# https://deeplylearning.fr/cours-theoriques-deep-learning/reglages-des-hyper-parametres/\n",
        "# initialize the initial learning rate, number of epochs to train for,\n",
        "# and batch size\n",
        "#INIT_LR = 1e-4\n",
        "# INIT_LR = 0.000146\n",
        "\n",
        "INIT_LR = 0.001\n",
        "#INIT_LR = 1e-4\n",
        "EPOCHS = 10\n",
        "BS = 64\n",
        "#BS = 32\n",
        "#BS = 64"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1G5PYjQ4pov"
      },
      "source": [
        "# Définition de l'optimizer (avec quelques paramètres qu'il faudra adapter à ses besoins)\n",
        "#opt = RAdam(total_steps=5000, warmup_proportion=0.1, min_lr=INIT_LR,  name='lr')\n",
        "# essayer de mettre 10000.0\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "opt = tfa.optimizers.RectifiedAdam(\n",
        "    lr=INIT_LR,\n",
        "    total_steps=5000,\n",
        "    warmup_proportion=0.1,\n",
        "    min_lr=INIT_LR\n",
        ")\n",
        "\"\"\"\n",
        "\"\"\"\n",
        "ranger = tfa.optimizers.Lookahead(opt, sync_period=6, slow_step_size=0.5)\n",
        "\"\"\"\n",
        "\n",
        "#https://www.pyimagesearch.com/2019/10/07/is-rectified-adam-actually-better-than-adam/\n",
        "\n",
        "opt = Adam(lr=INIT_LR, decay= INIT_LR/EPOCHS)\n",
        "\n"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIJGTqqW7AP8"
      },
      "source": [
        "# Utilisation de l'optimizer dans un model (déjà configuré avant)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
        "#model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K66FwB8DUmqw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26a76d22-9470-44be-f2b7-70484463dfd7"
      },
      "source": [
        "\n",
        "# train the head of the network\n",
        "print(\"[INFO] training head...\")\n",
        "\n",
        "H = model.fit(\n",
        "\taug.flow(trainX, trainY, batch_size=BS),\n",
        "\n",
        "\tvalidation_data=(testX, testY),\n",
        "\n",
        "\tepochs=EPOCHS\n",
        "  )\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] training head...\n",
            "Epoch 1/10\n",
            "73/73 [==============================] - 225s 3s/step - loss: 0.7664 - accuracy: 0.7007 - val_loss: 0.6303 - val_accuracy: 0.7923\n",
            "Epoch 2/10\n",
            "39/73 [===============>..............] - ETA: 1:32 - loss: 0.7679 - accuracy: 0.6965"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpJBmdhoUsb4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83d5f857-6f11-49b8-d540-f222512ae0ed"
      },
      "source": [
        "# make predictions on the testing set\n",
        "print(\"[INFO] evaluating network...\")\n",
        "predIdxs = model.predict(testX, batch_size=BS)\n",
        "\n",
        "# for each image in the testing set we need to find the index of the\n",
        "# label with corresponding largest predicted probability\n",
        "predIdxs = np.argmax(predIdxs, axis=1)\n",
        "\n",
        "# show a nicely formatted classification report\n",
        "print(classification_report(testY.argmax(axis=1), predIdxs))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] evaluating network...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       134\n",
            "           1       0.79      1.00      0.88       599\n",
            "           2       0.00      0.00      0.00        23\n",
            "\n",
            "    accuracy                           0.79       756\n",
            "   macro avg       0.26      0.33      0.29       756\n",
            "weighted avg       0.63      0.79      0.70       756\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqHRWEwB9Snl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f0db58c-1993-434a-f005-4b8a0d0e56d6"
      },
      "source": [
        "# serialize the model to disk\n",
        "print(\"[INFO] saving mask detector model...\")\n",
        "from datetime import datetime\n",
        "now = datetime.now()\n",
        "dt_string = now.strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
        "dt_string = \"mask_detector_Adam_\" + dt_string\n",
        "print(dt_string)\n",
        "model.save(\"Model/\"+ dt_string + \".h5\")\n"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] saving mask detector model...\n",
            "mask_detector_Adam_2021_01_21_21_21_09\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Im9EfZGMUwQX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "2642e225-75f3-41eb-9d6b-1b140c0cdc3c"
      },
      "source": [
        "# plot the training loss and accuracy\n",
        "\n",
        "\n",
        "N = EPOCHS\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\n",
        "plt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
        "plt.title(\"Training Loss and Accuracy\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend(loc=\"lower left\")\n",
        "plt.savefig(\"Model/\"+ dt_string+\".png\")\n",
        "plt.show()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLNDicBuLPoG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "97e9b257-29b5-4234-dd7c-db048433b630"
      },
      "source": [
        "from keras.models import Sequential\r\n",
        "from tensorflow.keras.layers import Conv2D\r\n",
        "from keras.layers import Activation, Dense, MaxPooling2D\r\n",
        "from keras.callbacks import ModelCheckpoint\r\n",
        "model = Sequential()\r\n",
        "model.add(Conv2D(200,(3,3),input_shape=face_images.shape[1:]))\r\n",
        "model.add(Activation('relu'))\r\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\r\n",
        "model.add(Conv2D(100,(3,3)))\r\n",
        "model.add(Activation('relu'))\r\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\r\n",
        "model.add(Flatten())\r\n",
        "model.add(Dropout(0.5))\r\n",
        "model.add(Dense(50,activation='relu'))\r\n",
        "model.add(Dense(3,activation='softmax'))\r\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics = ['acc'])\r\n",
        "model.summary()\r\n",
        "\r\n",
        "checkpoint=ModelCheckpoint('model-{epoch:03d}.model', monitor='val_loss', verbose = 0, save_best_only = True,mode='auto')\r\n",
        "H = model.fit(trainX,trainY,epochs = 20, callbacks = [checkpoint], validation_data=(testX, testY))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-2a29982d204c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mface_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mActivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'face_images' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zH1t2uNu5XQ"
      },
      "source": [
        "IMAGE_PATHS=['MaskTrainDataset/JPEGImages/00000a0f3efefef6.jpg',\n",
        "     'MaskTrainDataset/JPEGImages/000004243e3cbf37.jpg',\n",
        "     'MaskTrainDataset/JPEGImages/00008dfffc3c3f1c.jpg',\n",
        "     'MaskTrainDataset/JPEGImages/004c381010ffffff.jpg',\n",
        "     'MaskTrainDataset/JPEGImages/4848dc7e3efeacbc.jpg',\n",
        "     'MaskTrainDataset/JPEGImages/60e0ecefefececc0.jpg',\n",
        "     'MaskTrainDataset/JPEGImages/00c6cf8f8fdfcf8f.jpg',\n",
        "     'MaskTrainDataset/JPEGImages/0f37f662600081e1.jpg',\n",
        "     'MaskTrainDataset/JPEGImages/0000fdfcbc000660.jpg',\n",
        "     'MaskTrainDataset/JPEGImages/0ff99100498989cf.jpg',\n",
        "     'MaskTrainDataset/JPEGImages/00000c3e3e3e3c3e.jpg',\n",
        "     'MaskTrainDataset/JPEGImages/0000d8fe1f09bfff.jpg',\n",
        "     'MaskTrainDataset/JPEGImages/0f3f7f3720f0c000.jpg',\n",
        "     'MaskTrainDataset/JPEGImages/1b1bdfdac9c80102.jpg',\n",
        "     'MaskTrainDataset/JPEGImages/0fbf2f2c39b0f0f0.jpg',\n",
        "     'MaskTrainDataset/JPEGImages/00000000046e677f.jpg',\n",
        "     'MaskTrainDataset/JPEGImages/000000080e1e3e3e.jpg']\n",
        "print(IMAGE_PATHS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1d3_xLn99Bn4"
      },
      "source": [
        "#load the saved model\n",
        "\n",
        "import keras\n",
        "\n",
        "# serialize the model to disk\n",
        "print(\"[INFO] saving mask detector model...\")\n",
        "\n",
        "\n",
        "saved_model_path = \"Model\"\n",
        "\n",
        "\n",
        "#tf.saved_model.save(model, saved_model_path)\n",
        "model.save(saved_model_path)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjW-UZC8Hhvc"
      },
      "source": [
        "import tensorflow as tf\n",
        "#print(dt_string)\n",
        "model = keras.models.load_model(\"Model/\"+dt_string + \".h5\")\n",
        "detect_fn=tf.saved_model.load(\"Model\")\n",
        "#detect_fn = keras.models.load_model(\"Model/mask_detector_Adam_2020_12_25_15_34_55.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DASXgQ8gsJkx"
      },
      "source": [
        "\"\"\"\n",
        "for image_path in IMAGE_PATHS:\n",
        "\n",
        "    print('Running inference for {}... '.format(image_path), end='')\n",
        "\n",
        "    image_np = load_image_into_numpy_array(image_path)\n",
        "\n",
        "    # Things to try:\n",
        "    # Flip horizontally\n",
        "    # image_np = np.fliplr(image_np).copy()\n",
        "\n",
        "    # Convert image to grayscale\n",
        "    # image_np = np.tile(\n",
        "    #     np.mean(image_np, 2, keepdims=True), (1, 1, 3)).astype(np.uint8)\n",
        "\n",
        "    # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
        "    input_tensor = tf.convert_to_tensor(image_np)\n",
        "    # The model expects a batch of images, so add an axis with `tf.newaxis`.\n",
        "    input_tensor = input_tensor[tf.newaxis, ...]\n",
        "\n",
        "    #input_tensor = np.expand_dims(image_np, 0)\n",
        "    detections = detect_fn(input_tensor)\n",
        "\n",
        "    # All outputs are batches tensors.\n",
        "    # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
        "    # We're only interested in the first num_detections.\n",
        "    num_detections = int(detections.pop('num_detections'))\n",
        "    detections = {key: value[0, :num_detections].numpy()\n",
        "                   for key, value in detections.items()}\n",
        "    detections['num_detections'] = num_detections\n",
        "\n",
        "    # detection_classes should be ints.\n",
        "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
        "\n",
        "    image_np_with_detections = image_np.copy()\n",
        "\n",
        "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "          image_np_with_detections,\n",
        "          detections['detection_boxes'],\n",
        "          detections['detection_classes'],\n",
        "          detections['detection_scores'],\n",
        "          category_index,\n",
        "          use_normalized_coordinates=True,\n",
        "          max_boxes_to_draw=200,\n",
        "          min_score_thresh=.30,\n",
        "          agnostic_mode=False)\n",
        "\n",
        "    plt.figure()\n",
        "    plt.imshow(image_np_with_detections)\n",
        "    print('Done')\n",
        "plt.show()\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9rdTWfLsLFf"
      },
      "source": [
        "#load the saved model RAdam\n",
        "\"\"\"\n",
        "print('loading model...')\n",
        "opt = tfa.optimizers.RectifiedAdam(\n",
        "    lr=1e-3,\n",
        "    total_steps=10000,\n",
        "    warmup_proportion=0.1,\n",
        "    min_lr=1e-5,\n",
        ")\n",
        "\n",
        "ranger = tfa.optimizers.Lookahead(opt, sync_period=6, slow_step_size=0.5, name='Lookahead',)\n",
        "\n",
        "model = tf.keras.models.load_model('mask_detector_2020_12_19_07_20.h5', custom_objects={'Lookahead': ranger})\n",
        "\n",
        "print('model loaded')\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eF_dCAoWwn5"
      },
      "source": [
        "\n",
        "#train the saved model again \n",
        "print(\"[INFO] compiling model...\")\n",
        "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
        "\"\"\"\n",
        "opt = tfa.optimizers.RectifiedAdam(\n",
        "    lr=INIT_LR,\n",
        "    total_steps=5000,\n",
        "    warmup_proportion=0.1,\n",
        "    min_lr=INIT_LR\n",
        ")\n",
        "\"\"\"\n",
        "# Utilisation de l'optimizer dans un model (déjà configuré avant)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRfBDBxTrZ5o"
      },
      "source": [
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VG6gSS20WsTo"
      },
      "source": [
        "\n",
        "\n",
        "# train the head of the network\n",
        "print(\"[INFO] training head...\")\n",
        "\"\"\"\n",
        "H = model.fit(\n",
        "\taug.flow(trainX, trainY, batch_size=BS),\n",
        "\n",
        "\tvalidation_data=(testX, testY),\n",
        "\n",
        "\tepochs=EPOCHS\n",
        "  )\n",
        "\"\"\"\n",
        "H = model.fit(\n",
        "\taug.flow(trainX, trainY, batch_size=BS),\n",
        "\n",
        "\tvalidation_data=(testX, testY),\n",
        "\n",
        "\tepochs=EPOCHS,\n",
        "class_weight = {0:5 , 1:1, 2:10})\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtosBF9ZXNyo"
      },
      "source": [
        "#Evaluate the model again\n",
        "print(\"[INFO] evaluating network...\")\n",
        "predIdxs = model.predict(testX, batch_size=32)\n",
        "\n",
        "# for each image in the testing set we need to find the index of the\n",
        "# label with corresponding largest predicted probability\n",
        "predIdxs = np.argmax(predIdxs, axis=1)\n",
        "\n",
        "# show a nicely formatted classification report\n",
        "print(classification_report(testY.argmax(axis=1), predIdxs))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbz7lDVy9tMf"
      },
      "source": [
        "\n",
        "# plot the training loss and accuracy\n",
        "\n",
        "N = EPOCHS\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\n",
        "plt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
        "plt.title(\"Training Loss and Accuracy\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend(loc=\"lower left\")\n",
        "plt.savefig(\"Model/\"+ dt_string+\"_V1_1.png\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_F8gT6F9yZG"
      },
      "source": [
        "# serialize the model to disk\n",
        "print(\"[INFO] saving mask detector model...\")\n",
        "model.save(\"Model/\"+ dt_string+ \"_V1_1.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85_Cnuzoxp-u"
      },
      "source": [
        "\"\"\"\n",
        "for image_path in IMAGE_PATHS:\n",
        "\n",
        "    print('Running inference for {}... '.format(image_path), end='')\n",
        "\n",
        "    image_np = load_image_into_numpy_array(image_path)\n",
        "\n",
        "    # Things to try:\n",
        "    # Flip horizontally\n",
        "    image_np = np.fliplr(image_np).copy()\n",
        "\n",
        "    # Convert image to grayscale\n",
        "    image_np = np.tile(\n",
        "        np.mean(image_np, 2, keepdims=True), (1, 1, 3)).astype(np.uint8)\n",
        "\n",
        "    # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
        "    input_tensor = tf.convert_to_tensor(image_np)\n",
        "    # The model expects a batch of images, so add an axis with `tf.newaxis`.\n",
        "    input_tensor = input_tensor[tf.newaxis, ...]\n",
        "\n",
        "    input_tensor = np.expand_dims(image_np, 0)\n",
        "    detections = model(input_tensor)\n",
        "\n",
        "    # All outputs are batches tensors.\n",
        "    # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
        "    # We're only interested in the first num_detections.\n",
        "    num_detections = int(detections.pop('num_detections'))\n",
        "    detections = {key: value[0, :num_detections].numpy()\n",
        "                   for key, value in detections.items()}\n",
        "    detections['num_detections'] = num_detections\n",
        "\n",
        "    # detection_classes should be ints.\n",
        "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
        "\n",
        "    image_np_with_detections = image_np.copy()\n",
        "\n",
        "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "          image_np_with_detections,\n",
        "          detections['detection_boxes'],\n",
        "          detections['detection_classes'],\n",
        "          detections['detection_scores'],\n",
        "          category_index,\n",
        "          use_normalized_coordinates=True,\n",
        "          max_boxes_to_draw=200,\n",
        "          min_score_thresh=.30,\n",
        "          agnostic_mode=False)\n",
        "\n",
        "    plt.figure()\n",
        "    plt.imshow(image_np_with_detections)\n",
        "    print('Done')\n",
        "plt.show()\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}