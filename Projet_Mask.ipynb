{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Projet_Mask.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "history_visible": true,
      "mount_file_id": "1EX_eKMHP6zjFUp_c3aD7Q3aDwQNZOnHi",
      "authorship_tag": "ABX9TyMP6OXIYC3xvxuBMI46A2S/",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bruaba/mask_detection/blob/main/Projet_Mask.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Un-gY1PjvoK8"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Sun Nov 29 18:40:11 2020\n",
        "\n",
        "@author: cheikh\n",
        "\"\"\"\n",
        "#libraries\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import random as rand\n",
        "import keras\n",
        "import tensorflow_addons as tfa\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')   # Suppress Matplotlib warnings\n",
        "from PIL import Image\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.layers import AveragePooling2D\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "#from keras_radam import RAdam\n",
        "from imutils import paths\n",
        "from bs4 import BeautifulSoup"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JoSSVpfMzbA"
      },
      "source": [
        "def load_image_into_numpy_array(path):\n",
        "    \"\"\"Load an image from file into a numpy array.\n",
        "\n",
        "    Puts image into numpy array to feed into tensorflow graph.\n",
        "    Note that by convention we put it into a numpy array with shape\n",
        "    (height, width, channels), where channels=3 for RGB.\n",
        "\n",
        "    Args:\n",
        "      path: the file path to the image\n",
        "\n",
        "    Returns:\n",
        "      uint8 numpy array with shape (img_height, img_width, 3)\n",
        "    \"\"\"\n",
        "    return np.array(Image.open(path))"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsDZaMY-wlPG"
      },
      "source": [
        "def generate_box(obj):  \n",
        "    xmin = int(float(obj.find('xmin').text))\n",
        "    ymin = int(float(obj.find('ymin').text))\n",
        "    xmax = int(float(obj.find('xmax').text))\n",
        "    ymax = int(float(obj.find('ymax').text))\n",
        "    \n",
        "    return [xmin, ymin, xmax, ymax]\n",
        "\n",
        "#This function will give label assciated with each label and convert them to numbers\n",
        "def generate_label(obj):\n",
        "    if obj.find('name').text == \"with_mask\":\n",
        "        return 1\n",
        "    elif obj.find('name').text == \"mask_weared_incorrect\":\n",
        "        return 2\n",
        "#    elif obj.find('name').text == \"without_mask\":\n",
        "#        return 3\n",
        "    return 0\n",
        "\n",
        "#Using in this main function we parse the annotations file and get the objects out from them\n",
        "# Also we use the above two functions here \n",
        "def generate_target(image_id, file): \n",
        "    with open(file) as f:\n",
        "        data = f.read()\n",
        "        soup = BeautifulSoup(data, 'xml')\n",
        "        objects = soup.find_all('object')\n",
        "\n",
        "        num_objs = len(objects)\n",
        "\n",
        "        boxes = []\n",
        "        labels = []\n",
        "        for i in objects:\n",
        "            boxes.append(generate_box(i))\n",
        "            labels.append(generate_label(i))\n",
        "            \n",
        "        boxes=np.array(boxes)\n",
        "        labels=np.array(labels)\n",
        "\n",
        "        img_id = np.array(image_id)\n",
        "    # Annotation is in dictionary format\n",
        "        target = {}\n",
        "        target[\"boxes\"] = boxes\n",
        "        target[\"labels\"] = labels\n",
        "        \n",
        "        return (target,num_objs)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yT5qDo6VJWGM"
      },
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/MyDrive/Colab Notebooks\")\n",
        "#!ls"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Vn5dLPrwqwx",
        "outputId": "ea38fcd0-8194-40ed-c3ae-ad338d6aaabe"
      },
      "source": [
        "\n",
        "\n",
        "imgs = list(sorted(os.listdir(\"MaskTrainDataset/JPEGImages/\")))\n",
        "labels = list(sorted(os.listdir(\"MaskTrainDataset/Annotations/\")))\n",
        "#nombre d'images et de labels\n",
        "print(len(imgs))\n",
        "print(len(labels))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2655\n",
            "2655\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dm5bJc3T475"
      },
      "source": [
        "# Here we use the above functions and save results in lists\n",
        "targets=[]#store coordinates\n",
        "numobjs=[]#stores number of faces in each image\n",
        "#run the loop for number of images we have\n",
        "\n",
        "i=0\n",
        "for dirname, _, filenames in os.walk('MaskTrainDataset/Annotations/'):\n",
        "    for filename in filenames:\n",
        "        target, numobj = generate_target(i, os.path.join(dirname, filename))\n",
        "        targets.append(target)\n",
        "        numobjs.append(numobj)\n",
        "        i+=1\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2A1ou6Cyr6v"
      },
      "source": [
        "i=0\n",
        "face_images=[]\n",
        "face_labels=[]\n",
        "\n",
        "\n",
        "for dirname, _, filenames in os.walk('MaskTrainDataset/JPEGImages/'):\n",
        "    for filename in filenames:\n",
        "        img_path = os.path.join(dirname, filename)\n",
        "        img = cv2.imread(img_path)\n",
        "        for j in range(numobjs[i]):\n",
        "            locs = (targets[i]['boxes'][j])\n",
        "            img1 = img[int(locs[1]):int(locs[3]), int(locs[0]):int(locs[2])]       \n",
        "            try:\n",
        "                img1 = cv2.resize(img1, (224, 224))\n",
        "                img1 = img_to_array(img1)\n",
        "                img1 = preprocess_input(img1)\n",
        "                face_images.append(img1)\n",
        "                face_labels.append(targets[i]['labels'][j])\n",
        "            except cv2.error:\n",
        "                continue\n",
        "            \n",
        "        i+=1\n",
        "face_images= np.array(face_images, dtype=\"float32\")\n",
        "face_labels = np.array(face_labels)\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I49lrVD_5GGR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e84f272-abd7-4049-c228-b8e5ecf75e32"
      },
      "source": [
        "\n",
        "print(len(face_labels))\n",
        "print(len(face_images))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5773\n",
            "5773\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfQkzLrKUIxa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "751e964a-242c-4377-e3a2-8f2df40222f5"
      },
      "source": [
        "unique, counts = np.unique(face_labels, return_counts=True)\n",
        "print(dict(zip(unique, counts)))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0: 1322, 1: 4007, 2: 444}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvKGgPhYUM9q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a30358a2-dad6-4f9f-dd9a-4530a669d08b"
      },
      "source": [
        "#Encode the labels in one hot encode form\n",
        "\n",
        "#c'est pour transformer les données non numerique en numerique\n",
        "#ici les labels\n",
        "#https://stackoverrun.com/fr/q/12291556\n",
        "\n",
        "lb = LabelEncoder()\n",
        "labels = lb.fit_transform(face_labels)\n",
        "labels = to_categorical(labels)\n",
        "print(labels)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " ...\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7Bigd_QUcW4"
      },
      "source": [
        "#divide data into training and testing sets\n",
        "(trainX, testX, trainY, testY) = train_test_split(face_images, labels,\n",
        "    test_size=0.20, stratify=labels, random_state=42)\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8HVBynk5Axt"
      },
      "source": [
        "# construct the training image generator for data augmentation\n",
        "\"\"\"\n",
        "La classe ImageDataGenerator garantit que le modèle reçoit de nouvelles variations des images à chaque époque. \n",
        "Mais il ne renvoie que les images transformées et ne les ajoute pas au corpus original d'images. \n",
        "Si c'était effectivement le cas, alors le modèle verrait les images originales plusieurs fois, ce qui sur-adapterait certainement notre modèle.\n",
        "\n",
        "Un autre avantage d'ImageDataGenerator est qu'il nécessite une moindre utilisation de la mémoire. \n",
        "En effet, sans utiliser cette classe, nous chargeons toutes les images en même temps. Mais en l'utilisant, nous chargeons les images par lots, ce qui économise beaucoup de mémoire.\n",
        "\"\"\"\n",
        "#https://www.analyticsvidhya.com/blog/2020/08/image-augmentation-on-the-fly-using-keras-imagedatagenerator/\n",
        "aug = ImageDataGenerator(\n",
        "\trotation_range=25,\n",
        "\tzoom_range=0.15,\n",
        "\twidth_shift_range=0.2,\n",
        "\theight_shift_range=0.2,\n",
        "\tshear_range=0.15,\n",
        "  vertical_flip = True,\n",
        "\tfill_mode=\"nearest\")"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYCan6QkUSfv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1876cc92-5c7b-4d28-915a-f446b38322ce"
      },
      "source": [
        "#https://deeplylearning.fr/cours-theoriques-deep-learning/transfer-learning/\n",
        "\n",
        "\n",
        "# load the MobileNetV2 network, ensuring the head FC layer sets are\n",
        "# left off\n",
        "#Notamment, MobileNetV2 + SSDLite est 20 fois plus efficace et 10 fois plus petit, tout en surpassant YOLOv2 sur l'ensemble de données COCO.\n",
        "#https://towardsdatascience.com/review-mobilenetv2-light-weight-model-image-classification-8febb490e61c\n",
        "\n",
        "#https://keras.io/api/applications/mobilenet/\n",
        "\n",
        "baseModel = MobileNetV2(weights=\"imagenet\", include_top=False,\n",
        "                        input_shape=(224, 224, 3))\n",
        "\n",
        "# construct the head of the model that will be placed on top of the\n",
        "# the base model\n",
        "headModel = baseModel.output\n",
        "#https://www.machinecurve.com/index.php/2020/01/30/what-are-max-pooling-average-pooling-global-max-pooling-and-global-average-pooling/\n",
        "headModel = AveragePooling2D(pool_size=(7, 7))(headModel)\n",
        "#appaltir\n",
        "headModel = Flatten(name=\"flatten\")(headModel)\n",
        "\n",
        "\n",
        "# headModel = Dense(256, activation=\"relu\")(headModel)\n",
        "headModel = Dense(128, activation=\"relu\")(headModel)\n",
        "# headModel = Dense(512, activation=\"sigmoid\")(headModel)\n",
        "# supprimer certain noeud\n",
        "headModel = Dropout(0.5)(headModel)\n",
        "# headModel = Dropout(0.25)(headModel)\n",
        "headModel = Dense(3, activation=\"softmax\")(headModel)\n",
        "\n",
        "\n",
        "# place the head FC model on top of the base model (this will become\n",
        "# the actual model we will train)\n",
        "model = Model(inputs=baseModel.input, outputs=headModel)\n",
        "print(model.summary())\n",
        "\n",
        "# loop over all layers in the base model and freeze them so they will\n",
        "# *not* be updated during the first training process\n",
        "for layer in baseModel.layers:\n",
        "\tlayer.trainable = False"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_6\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_7 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Conv1 (Conv2D)                  (None, 112, 112, 32) 864         input_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bn_Conv1 (BatchNormalization)   (None, 112, 112, 32) 128         Conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "Conv1_relu (ReLU)               (None, 112, 112, 32) 0           bn_Conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "expanded_conv_depthwise (Depthw (None, 112, 112, 32) 288         Conv1_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "expanded_conv_depthwise_BN (Bat (None, 112, 112, 32) 128         expanded_conv_depthwise[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "expanded_conv_depthwise_relu (R (None, 112, 112, 32) 0           expanded_conv_depthwise_BN[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "expanded_conv_project (Conv2D)  (None, 112, 112, 16) 512         expanded_conv_depthwise_relu[0][0\n",
            "__________________________________________________________________________________________________\n",
            "expanded_conv_project_BN (Batch (None, 112, 112, 16) 64          expanded_conv_project[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block_1_expand (Conv2D)         (None, 112, 112, 96) 1536        expanded_conv_project_BN[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "block_1_expand_BN (BatchNormali (None, 112, 112, 96) 384         block_1_expand[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block_1_expand_relu (ReLU)      (None, 112, 112, 96) 0           block_1_expand_BN[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_1_pad (ZeroPadding2D)     (None, 113, 113, 96) 0           block_1_expand_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_1_depthwise (DepthwiseCon (None, 56, 56, 96)   864         block_1_pad[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block_1_depthwise_BN (BatchNorm (None, 56, 56, 96)   384         block_1_depthwise[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_1_depthwise_relu (ReLU)   (None, 56, 56, 96)   0           block_1_depthwise_BN[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_1_project (Conv2D)        (None, 56, 56, 24)   2304        block_1_depthwise_relu[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block_1_project_BN (BatchNormal (None, 56, 56, 24)   96          block_1_project[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_2_expand (Conv2D)         (None, 56, 56, 144)  3456        block_1_project_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_2_expand_BN (BatchNormali (None, 56, 56, 144)  576         block_2_expand[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block_2_expand_relu (ReLU)      (None, 56, 56, 144)  0           block_2_expand_BN[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_2_depthwise (DepthwiseCon (None, 56, 56, 144)  1296        block_2_expand_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_2_depthwise_BN (BatchNorm (None, 56, 56, 144)  576         block_2_depthwise[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_2_depthwise_relu (ReLU)   (None, 56, 56, 144)  0           block_2_depthwise_BN[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_2_project (Conv2D)        (None, 56, 56, 24)   3456        block_2_depthwise_relu[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block_2_project_BN (BatchNormal (None, 56, 56, 24)   96          block_2_project[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_2_add (Add)               (None, 56, 56, 24)   0           block_1_project_BN[0][0]         \n",
            "                                                                 block_2_project_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_3_expand (Conv2D)         (None, 56, 56, 144)  3456        block_2_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block_3_expand_BN (BatchNormali (None, 56, 56, 144)  576         block_3_expand[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block_3_expand_relu (ReLU)      (None, 56, 56, 144)  0           block_3_expand_BN[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_3_pad (ZeroPadding2D)     (None, 57, 57, 144)  0           block_3_expand_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_3_depthwise (DepthwiseCon (None, 28, 28, 144)  1296        block_3_pad[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block_3_depthwise_BN (BatchNorm (None, 28, 28, 144)  576         block_3_depthwise[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_3_depthwise_relu (ReLU)   (None, 28, 28, 144)  0           block_3_depthwise_BN[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_3_project (Conv2D)        (None, 28, 28, 32)   4608        block_3_depthwise_relu[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block_3_project_BN (BatchNormal (None, 28, 28, 32)   128         block_3_project[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_4_expand (Conv2D)         (None, 28, 28, 192)  6144        block_3_project_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_4_expand_BN (BatchNormali (None, 28, 28, 192)  768         block_4_expand[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block_4_expand_relu (ReLU)      (None, 28, 28, 192)  0           block_4_expand_BN[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_4_depthwise (DepthwiseCon (None, 28, 28, 192)  1728        block_4_expand_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_4_depthwise_BN (BatchNorm (None, 28, 28, 192)  768         block_4_depthwise[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_4_depthwise_relu (ReLU)   (None, 28, 28, 192)  0           block_4_depthwise_BN[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_4_project (Conv2D)        (None, 28, 28, 32)   6144        block_4_depthwise_relu[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block_4_project_BN (BatchNormal (None, 28, 28, 32)   128         block_4_project[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_4_add (Add)               (None, 28, 28, 32)   0           block_3_project_BN[0][0]         \n",
            "                                                                 block_4_project_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_5_expand (Conv2D)         (None, 28, 28, 192)  6144        block_4_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block_5_expand_BN (BatchNormali (None, 28, 28, 192)  768         block_5_expand[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block_5_expand_relu (ReLU)      (None, 28, 28, 192)  0           block_5_expand_BN[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_5_depthwise (DepthwiseCon (None, 28, 28, 192)  1728        block_5_expand_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_5_depthwise_BN (BatchNorm (None, 28, 28, 192)  768         block_5_depthwise[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_5_depthwise_relu (ReLU)   (None, 28, 28, 192)  0           block_5_depthwise_BN[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_5_project (Conv2D)        (None, 28, 28, 32)   6144        block_5_depthwise_relu[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block_5_project_BN (BatchNormal (None, 28, 28, 32)   128         block_5_project[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_5_add (Add)               (None, 28, 28, 32)   0           block_4_add[0][0]                \n",
            "                                                                 block_5_project_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_6_expand (Conv2D)         (None, 28, 28, 192)  6144        block_5_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block_6_expand_BN (BatchNormali (None, 28, 28, 192)  768         block_6_expand[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block_6_expand_relu (ReLU)      (None, 28, 28, 192)  0           block_6_expand_BN[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_6_pad (ZeroPadding2D)     (None, 29, 29, 192)  0           block_6_expand_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_6_depthwise (DepthwiseCon (None, 14, 14, 192)  1728        block_6_pad[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block_6_depthwise_BN (BatchNorm (None, 14, 14, 192)  768         block_6_depthwise[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_6_depthwise_relu (ReLU)   (None, 14, 14, 192)  0           block_6_depthwise_BN[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_6_project (Conv2D)        (None, 14, 14, 64)   12288       block_6_depthwise_relu[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block_6_project_BN (BatchNormal (None, 14, 14, 64)   256         block_6_project[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_7_expand (Conv2D)         (None, 14, 14, 384)  24576       block_6_project_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_7_expand_BN (BatchNormali (None, 14, 14, 384)  1536        block_7_expand[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block_7_expand_relu (ReLU)      (None, 14, 14, 384)  0           block_7_expand_BN[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_7_depthwise (DepthwiseCon (None, 14, 14, 384)  3456        block_7_expand_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_7_depthwise_BN (BatchNorm (None, 14, 14, 384)  1536        block_7_depthwise[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_7_depthwise_relu (ReLU)   (None, 14, 14, 384)  0           block_7_depthwise_BN[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_7_project (Conv2D)        (None, 14, 14, 64)   24576       block_7_depthwise_relu[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block_7_project_BN (BatchNormal (None, 14, 14, 64)   256         block_7_project[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_7_add (Add)               (None, 14, 14, 64)   0           block_6_project_BN[0][0]         \n",
            "                                                                 block_7_project_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_8_expand (Conv2D)         (None, 14, 14, 384)  24576       block_7_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block_8_expand_BN (BatchNormali (None, 14, 14, 384)  1536        block_8_expand[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block_8_expand_relu (ReLU)      (None, 14, 14, 384)  0           block_8_expand_BN[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_8_depthwise (DepthwiseCon (None, 14, 14, 384)  3456        block_8_expand_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_8_depthwise_BN (BatchNorm (None, 14, 14, 384)  1536        block_8_depthwise[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_8_depthwise_relu (ReLU)   (None, 14, 14, 384)  0           block_8_depthwise_BN[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_8_project (Conv2D)        (None, 14, 14, 64)   24576       block_8_depthwise_relu[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block_8_project_BN (BatchNormal (None, 14, 14, 64)   256         block_8_project[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_8_add (Add)               (None, 14, 14, 64)   0           block_7_add[0][0]                \n",
            "                                                                 block_8_project_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_9_expand (Conv2D)         (None, 14, 14, 384)  24576       block_8_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block_9_expand_BN (BatchNormali (None, 14, 14, 384)  1536        block_9_expand[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block_9_expand_relu (ReLU)      (None, 14, 14, 384)  0           block_9_expand_BN[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_9_depthwise (DepthwiseCon (None, 14, 14, 384)  3456        block_9_expand_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_9_depthwise_BN (BatchNorm (None, 14, 14, 384)  1536        block_9_depthwise[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_9_depthwise_relu (ReLU)   (None, 14, 14, 384)  0           block_9_depthwise_BN[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_9_project (Conv2D)        (None, 14, 14, 64)   24576       block_9_depthwise_relu[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block_9_project_BN (BatchNormal (None, 14, 14, 64)   256         block_9_project[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_9_add (Add)               (None, 14, 14, 64)   0           block_8_add[0][0]                \n",
            "                                                                 block_9_project_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_10_expand (Conv2D)        (None, 14, 14, 384)  24576       block_9_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block_10_expand_BN (BatchNormal (None, 14, 14, 384)  1536        block_10_expand[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_10_expand_relu (ReLU)     (None, 14, 14, 384)  0           block_10_expand_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_10_depthwise (DepthwiseCo (None, 14, 14, 384)  3456        block_10_expand_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_10_depthwise_BN (BatchNor (None, 14, 14, 384)  1536        block_10_depthwise[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_10_depthwise_relu (ReLU)  (None, 14, 14, 384)  0           block_10_depthwise_BN[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block_10_project (Conv2D)       (None, 14, 14, 96)   36864       block_10_depthwise_relu[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block_10_project_BN (BatchNorma (None, 14, 14, 96)   384         block_10_project[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_11_expand (Conv2D)        (None, 14, 14, 576)  55296       block_10_project_BN[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_11_expand_BN (BatchNormal (None, 14, 14, 576)  2304        block_11_expand[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_11_expand_relu (ReLU)     (None, 14, 14, 576)  0           block_11_expand_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_11_depthwise (DepthwiseCo (None, 14, 14, 576)  5184        block_11_expand_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_11_depthwise_BN (BatchNor (None, 14, 14, 576)  2304        block_11_depthwise[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_11_depthwise_relu (ReLU)  (None, 14, 14, 576)  0           block_11_depthwise_BN[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block_11_project (Conv2D)       (None, 14, 14, 96)   55296       block_11_depthwise_relu[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block_11_project_BN (BatchNorma (None, 14, 14, 96)   384         block_11_project[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_11_add (Add)              (None, 14, 14, 96)   0           block_10_project_BN[0][0]        \n",
            "                                                                 block_11_project_BN[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_12_expand (Conv2D)        (None, 14, 14, 576)  55296       block_11_add[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block_12_expand_BN (BatchNormal (None, 14, 14, 576)  2304        block_12_expand[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_12_expand_relu (ReLU)     (None, 14, 14, 576)  0           block_12_expand_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_12_depthwise (DepthwiseCo (None, 14, 14, 576)  5184        block_12_expand_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_12_depthwise_BN (BatchNor (None, 14, 14, 576)  2304        block_12_depthwise[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_12_depthwise_relu (ReLU)  (None, 14, 14, 576)  0           block_12_depthwise_BN[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block_12_project (Conv2D)       (None, 14, 14, 96)   55296       block_12_depthwise_relu[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block_12_project_BN (BatchNorma (None, 14, 14, 96)   384         block_12_project[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_12_add (Add)              (None, 14, 14, 96)   0           block_11_add[0][0]               \n",
            "                                                                 block_12_project_BN[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_13_expand (Conv2D)        (None, 14, 14, 576)  55296       block_12_add[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block_13_expand_BN (BatchNormal (None, 14, 14, 576)  2304        block_13_expand[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_13_expand_relu (ReLU)     (None, 14, 14, 576)  0           block_13_expand_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_13_pad (ZeroPadding2D)    (None, 15, 15, 576)  0           block_13_expand_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_13_depthwise (DepthwiseCo (None, 7, 7, 576)    5184        block_13_pad[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block_13_depthwise_BN (BatchNor (None, 7, 7, 576)    2304        block_13_depthwise[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_13_depthwise_relu (ReLU)  (None, 7, 7, 576)    0           block_13_depthwise_BN[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block_13_project (Conv2D)       (None, 7, 7, 160)    92160       block_13_depthwise_relu[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block_13_project_BN (BatchNorma (None, 7, 7, 160)    640         block_13_project[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_14_expand (Conv2D)        (None, 7, 7, 960)    153600      block_13_project_BN[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_14_expand_BN (BatchNormal (None, 7, 7, 960)    3840        block_14_expand[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_14_expand_relu (ReLU)     (None, 7, 7, 960)    0           block_14_expand_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_14_depthwise (DepthwiseCo (None, 7, 7, 960)    8640        block_14_expand_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_14_depthwise_BN (BatchNor (None, 7, 7, 960)    3840        block_14_depthwise[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_14_depthwise_relu (ReLU)  (None, 7, 7, 960)    0           block_14_depthwise_BN[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block_14_project (Conv2D)       (None, 7, 7, 160)    153600      block_14_depthwise_relu[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block_14_project_BN (BatchNorma (None, 7, 7, 160)    640         block_14_project[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_14_add (Add)              (None, 7, 7, 160)    0           block_13_project_BN[0][0]        \n",
            "                                                                 block_14_project_BN[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_15_expand (Conv2D)        (None, 7, 7, 960)    153600      block_14_add[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block_15_expand_BN (BatchNormal (None, 7, 7, 960)    3840        block_15_expand[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_15_expand_relu (ReLU)     (None, 7, 7, 960)    0           block_15_expand_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_15_depthwise (DepthwiseCo (None, 7, 7, 960)    8640        block_15_expand_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_15_depthwise_BN (BatchNor (None, 7, 7, 960)    3840        block_15_depthwise[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_15_depthwise_relu (ReLU)  (None, 7, 7, 960)    0           block_15_depthwise_BN[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block_15_project (Conv2D)       (None, 7, 7, 160)    153600      block_15_depthwise_relu[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block_15_project_BN (BatchNorma (None, 7, 7, 160)    640         block_15_project[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_15_add (Add)              (None, 7, 7, 160)    0           block_14_add[0][0]               \n",
            "                                                                 block_15_project_BN[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_16_expand (Conv2D)        (None, 7, 7, 960)    153600      block_15_add[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block_16_expand_BN (BatchNormal (None, 7, 7, 960)    3840        block_16_expand[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_16_expand_relu (ReLU)     (None, 7, 7, 960)    0           block_16_expand_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_16_depthwise (DepthwiseCo (None, 7, 7, 960)    8640        block_16_expand_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_16_depthwise_BN (BatchNor (None, 7, 7, 960)    3840        block_16_depthwise[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_16_depthwise_relu (ReLU)  (None, 7, 7, 960)    0           block_16_depthwise_BN[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block_16_project (Conv2D)       (None, 7, 7, 320)    307200      block_16_depthwise_relu[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block_16_project_BN (BatchNorma (None, 7, 7, 320)    1280        block_16_project[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "Conv_1 (Conv2D)                 (None, 7, 7, 1280)   409600      block_16_project_BN[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Conv_1_bn (BatchNormalization)  (None, 7, 7, 1280)   5120        Conv_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "out_relu (ReLU)                 (None, 7, 7, 1280)   0           Conv_1_bn[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 1, 1, 1280)   0           out_relu[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 1280)         0           average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_12 (Dense)                (None, 128)          163968      flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 128)          0           dense_12[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_13 (Dense)                (None, 3)            387         dropout_6[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 2,422,339\n",
            "Trainable params: 2,388,227\n",
            "Non-trainable params: 34,112\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Zp82ReD4xLv"
      },
      "source": [
        "#Free some space.I did this tep as the notebook was running out of space while training\n",
        "#del targets,face_images,face_labels"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATU92ddD48B2"
      },
      "source": [
        "# https://deeplylearning.fr/cours-theoriques-deep-learning/reglages-des-hyper-parametres/\n",
        "# initialize the initial learning rate, number of epochs to train for,\n",
        "# and batch size\n",
        "#INIT_LR = 1e-4\n",
        "# INIT_LR = 0.000146\n",
        "#INIT_LR = 0.001\n",
        "INIT_LR = 1e-4\n",
        "EPOCHS = 20\n",
        "BS = 32\n",
        "#BS = 32\n",
        "#BS = 64"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1G5PYjQ4pov"
      },
      "source": [
        "# Définition de l'optimizer (avec quelques paramètres qu'il faudra adapter à ses besoins)\n",
        "#opt = RAdam(total_steps=5000, warmup_proportion=0.1, min_lr=INIT_LR,  name='lr')\n",
        "# essayer de mettre 10000.0\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "opt = tfa.optimizers.RectifiedAdam(\n",
        "    lr=INIT_LR,\n",
        "    total_steps=5000,\n",
        "    warmup_proportion=0.1,\n",
        "    min_lr=INIT_LR\n",
        ")\n",
        "\"\"\"\n",
        "\"\"\"\n",
        "ranger = tfa.optimizers.Lookahead(opt, sync_period=6, slow_step_size=0.5)\n",
        "\"\"\"\n",
        "\n",
        "#https://www.pyimagesearch.com/2019/10/07/is-rectified-adam-actually-better-than-adam/\n",
        "\n",
        "opt = Adam(lr=INIT_LR, decay= INIT_LR/EPOCHS)\n",
        "\n"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLNDicBuLPoG",
        "outputId": "76cf08bc-a19b-4833-b5f8-87c95a104ee9"
      },
      "source": [
        "from keras.models import Sequential\r\n",
        "from tensorflow.keras.layers import Conv2D\r\n",
        "from keras.layers import Activation, Dense, MaxPooling2D\r\n",
        "from keras.callbacks import ModelCheckpoint\r\n",
        "model = Sequential()\r\n",
        "model.add(Conv2D(200,(3,3),input_shape=face_images.shape[1:]))\r\n",
        "model.add(Activation('relu'))\r\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\r\n",
        "model.add(Conv2D(100,(3,3)))\r\n",
        "model.add(Activation('relu'))\r\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\r\n",
        "model.add(Flatten())\r\n",
        "model.add(Dropout(0.5))\r\n",
        "model.add(Dense(50,activation='relu'))\r\n",
        "model.add(Dense(3,activation='softmax'))\r\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics = ['acc'])\r\n",
        "model.summary()\r\n",
        "\r\n",
        "checkpoint=ModelCheckpoint('model-{epoch:03d}.model', monitor='val_loss', verbose = 0, save_best_only = True,mode='auto')\r\n",
        "history = model.fit(trainX,trainY,epochs = 20, callbacks = [checkpoint], validation_split = 0.2)"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_9 (Conv2D)            (None, 222, 222, 200)     5600      \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 222, 222, 200)     0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 111, 111, 200)     0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 109, 109, 100)     180100    \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 109, 109, 100)     0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 54, 54, 100)       0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 291600)            0         \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 291600)            0         \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 50)                14580050  \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 3)                 153       \n",
            "=================================================================\n",
            "Total params: 14,765,903\n",
            "Trainable params: 14,765,903\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "116/116 [==============================] - 50s 405ms/step - loss: 1.1834 - acc: 0.6485 - val_loss: 0.8014 - val_acc: 0.6872\n",
            "INFO:tensorflow:Assets written to: model-001.model/assets\n",
            "Epoch 2/20\n",
            "116/116 [==============================] - 44s 382ms/step - loss: 0.8299 - acc: 0.6850 - val_loss: 0.8373 - val_acc: 0.6861\n",
            "Epoch 3/20\n",
            "116/116 [==============================] - 44s 380ms/step - loss: 0.8210 - acc: 0.6873 - val_loss: 0.7999 - val_acc: 0.6872\n",
            "INFO:tensorflow:Assets written to: model-003.model/assets\n",
            "Epoch 4/20\n",
            "116/116 [==============================] - 44s 379ms/step - loss: 0.7933 - acc: 0.7060 - val_loss: 0.8282 - val_acc: 0.6872\n",
            "Epoch 5/20\n",
            "116/116 [==============================] - 44s 379ms/step - loss: 0.7717 - acc: 0.7103 - val_loss: 0.7929 - val_acc: 0.6872\n",
            "INFO:tensorflow:Assets written to: model-005.model/assets\n",
            "Epoch 6/20\n",
            "116/116 [==============================] - 44s 379ms/step - loss: 0.7751 - acc: 0.7059 - val_loss: 0.7887 - val_acc: 0.6872\n",
            "INFO:tensorflow:Assets written to: model-006.model/assets\n",
            "Epoch 7/20\n",
            "116/116 [==============================] - 44s 378ms/step - loss: 0.7853 - acc: 0.7036 - val_loss: 0.7958 - val_acc: 0.6872\n",
            "Epoch 8/20\n",
            "116/116 [==============================] - 44s 378ms/step - loss: 0.7812 - acc: 0.7023 - val_loss: 0.7915 - val_acc: 0.6872\n",
            "Epoch 9/20\n",
            "116/116 [==============================] - 44s 377ms/step - loss: 0.7904 - acc: 0.6915 - val_loss: 0.7999 - val_acc: 0.6872\n",
            "Epoch 10/20\n",
            "116/116 [==============================] - 44s 376ms/step - loss: 0.7856 - acc: 0.6894 - val_loss: 0.8166 - val_acc: 0.6872\n",
            "Epoch 11/20\n",
            "116/116 [==============================] - 44s 376ms/step - loss: 0.7887 - acc: 0.7006 - val_loss: 0.7864 - val_acc: 0.6872\n",
            "INFO:tensorflow:Assets written to: model-011.model/assets\n",
            "Epoch 12/20\n",
            "116/116 [==============================] - 44s 376ms/step - loss: 0.7751 - acc: 0.7011 - val_loss: 0.7842 - val_acc: 0.6872\n",
            "INFO:tensorflow:Assets written to: model-012.model/assets\n",
            "Epoch 13/20\n",
            "116/116 [==============================] - 44s 376ms/step - loss: 0.7846 - acc: 0.6909 - val_loss: 0.7895 - val_acc: 0.6872\n",
            "Epoch 14/20\n",
            "116/116 [==============================] - 44s 375ms/step - loss: 0.8057 - acc: 0.6928 - val_loss: 0.7868 - val_acc: 0.6872\n",
            "Epoch 15/20\n",
            "116/116 [==============================] - 44s 376ms/step - loss: 0.8071 - acc: 0.6935 - val_loss: 0.7928 - val_acc: 0.6872\n",
            "Epoch 16/20\n",
            "116/116 [==============================] - 43s 375ms/step - loss: 0.7798 - acc: 0.6998 - val_loss: 0.7884 - val_acc: 0.6872\n",
            "Epoch 17/20\n",
            "116/116 [==============================] - 43s 374ms/step - loss: 0.7764 - acc: 0.7019 - val_loss: 0.7882 - val_acc: 0.6872\n",
            "Epoch 18/20\n",
            "116/116 [==============================] - 43s 375ms/step - loss: 0.7967 - acc: 0.6830 - val_loss: 0.7948 - val_acc: 0.6872\n",
            "Epoch 19/20\n",
            "116/116 [==============================] - 43s 374ms/step - loss: 0.7836 - acc: 0.6946 - val_loss: 0.7932 - val_acc: 0.6872\n",
            "Epoch 20/20\n",
            "116/116 [==============================] - 43s 373ms/step - loss: 0.7698 - acc: 0.7011 - val_loss: 0.7953 - val_acc: 0.6872\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIJGTqqW7AP8"
      },
      "source": [
        "# Utilisation de l'optimizer dans un model (déjà configuré avant)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
        "#model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K66FwB8DUmqw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "668c1b44-b886-40c3-973b-a36f9c549dc7"
      },
      "source": [
        "\n",
        "# train the head of the network\n",
        "print(\"[INFO] training head...\")\n",
        "\n",
        "H = model.fit(\n",
        "\taug.flow(trainX, trainY, batch_size=BS),\n",
        "\n",
        "\tvalidation_data=(testX, testY),\n",
        "\n",
        "\tepochs=EPOCHS\n",
        "  )\n",
        "\n"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] training head...\n",
            "Epoch 1/20\n",
            "145/145 [==============================] - 60s 398ms/step - loss: 1.0910 - accuracy: 0.5928 - val_loss: 0.8233 - val_accuracy: 0.6857\n",
            "Epoch 2/20\n",
            "145/145 [==============================] - 56s 384ms/step - loss: 0.8489 - accuracy: 0.6661 - val_loss: 0.8084 - val_accuracy: 0.6909\n",
            "Epoch 3/20\n",
            "145/145 [==============================] - 55s 382ms/step - loss: 0.8161 - accuracy: 0.6763 - val_loss: 0.8062 - val_accuracy: 0.6935\n",
            "Epoch 4/20\n",
            "145/145 [==============================] - 56s 383ms/step - loss: 0.8223 - accuracy: 0.6728 - val_loss: 0.8009 - val_accuracy: 0.6935\n",
            "Epoch 5/20\n",
            "145/145 [==============================] - 55s 382ms/step - loss: 0.8028 - accuracy: 0.6907 - val_loss: 0.7985 - val_accuracy: 0.6944\n",
            "Epoch 6/20\n",
            "145/145 [==============================] - 55s 382ms/step - loss: 0.7739 - accuracy: 0.7066 - val_loss: 0.7964 - val_accuracy: 0.6944\n",
            "Epoch 7/20\n",
            "145/145 [==============================] - 54s 376ms/step - loss: 0.8062 - accuracy: 0.6851 - val_loss: 0.7940 - val_accuracy: 0.6944\n",
            "Epoch 8/20\n",
            "145/145 [==============================] - 54s 376ms/step - loss: 0.7865 - accuracy: 0.6956 - val_loss: 0.7945 - val_accuracy: 0.6944\n",
            "Epoch 9/20\n",
            "145/145 [==============================] - 54s 372ms/step - loss: 0.7782 - accuracy: 0.7011 - val_loss: 0.7969 - val_accuracy: 0.6944\n",
            "Epoch 10/20\n",
            "145/145 [==============================] - 54s 375ms/step - loss: 0.7915 - accuracy: 0.6962 - val_loss: 0.7921 - val_accuracy: 0.6944\n",
            "Epoch 11/20\n",
            "145/145 [==============================] - 54s 374ms/step - loss: 0.7660 - accuracy: 0.7026 - val_loss: 0.7961 - val_accuracy: 0.6944\n",
            "Epoch 12/20\n",
            "145/145 [==============================] - 55s 376ms/step - loss: 0.7950 - accuracy: 0.6849 - val_loss: 0.7932 - val_accuracy: 0.6944\n",
            "Epoch 13/20\n",
            "145/145 [==============================] - 55s 376ms/step - loss: 0.7927 - accuracy: 0.6897 - val_loss: 0.7936 - val_accuracy: 0.6944\n",
            "Epoch 14/20\n",
            "145/145 [==============================] - 54s 375ms/step - loss: 0.7745 - accuracy: 0.6997 - val_loss: 0.7983 - val_accuracy: 0.6944\n",
            "Epoch 15/20\n",
            "145/145 [==============================] - 54s 369ms/step - loss: 0.7637 - accuracy: 0.7017 - val_loss: 0.7930 - val_accuracy: 0.6944\n",
            "Epoch 16/20\n",
            "145/145 [==============================] - 53s 366ms/step - loss: 0.7631 - accuracy: 0.7013 - val_loss: 0.7986 - val_accuracy: 0.6935\n",
            "Epoch 17/20\n",
            "145/145 [==============================] - 53s 364ms/step - loss: 0.7534 - accuracy: 0.7104 - val_loss: 0.7937 - val_accuracy: 0.6944\n",
            "Epoch 18/20\n",
            "145/145 [==============================] - 53s 366ms/step - loss: 0.7785 - accuracy: 0.6913 - val_loss: 0.7930 - val_accuracy: 0.6944\n",
            "Epoch 19/20\n",
            "145/145 [==============================] - 53s 366ms/step - loss: 0.7627 - accuracy: 0.7013 - val_loss: 0.8002 - val_accuracy: 0.6918\n",
            "Epoch 20/20\n",
            "145/145 [==============================] - 53s 364ms/step - loss: 0.7801 - accuracy: 0.6991 - val_loss: 0.7969 - val_accuracy: 0.6926\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpJBmdhoUsb4"
      },
      "source": [
        "# make predictions on the testing set\n",
        "print(\"[INFO] evaluating network...\")\n",
        "predIdxs = model.predict(testX, batch_size=BS)\n",
        "\n",
        "# for each image in the testing set we need to find the index of the\n",
        "# label with corresponding largest predicted probability\n",
        "predIdxs = np.argmax(predIdxs, axis=1)\n",
        "\n",
        "# show a nicely formatted classification report\n",
        "print(classification_report(testY.argmax(axis=1), predIdxs))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqHRWEwB9Snl"
      },
      "source": [
        "# serialize the model to disk\n",
        "print(\"[INFO] saving mask detector model...\")\n",
        "from datetime import datetime\n",
        "now = datetime.now()\n",
        "dt_string = now.strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
        "dt_string = \"mask_detector_Adam_\" + dt_string\n",
        "print(dt_string)\n",
        "model.save(\"Model/\"+ dt_string + \".h5\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Im9EfZGMUwQX"
      },
      "source": [
        "# plot the training loss and accuracy\n",
        "\n",
        "\n",
        "N = EPOCHS\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\n",
        "plt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
        "plt.title(\"Training Loss and Accuracy\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend(loc=\"lower left\")\n",
        "plt.savefig(\"Model/\"+ dt_string+\".png\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zH1t2uNu5XQ"
      },
      "source": [
        "IMAGE_PATHS=['MaskTrainDataset/JPEGImages/00000a0f3efefef6.jpg',\n",
        "     'MaskTrainDataset/JPEGImages/000004243e3cbf37.jpg',\n",
        "     'MaskTrainDataset/JPEGImages/00008dfffc3c3f1c.jpg',\n",
        "     'MaskTrainDataset/JPEGImages/004c381010ffffff.jpg',\n",
        "     'MaskTrainDataset/JPEGImages/4848dc7e3efeacbc.jpg',\n",
        "     'MaskTrainDataset/JPEGImages/60e0ecefefececc0.jpg',\n",
        "     'MaskTrainDataset/JPEGImages/00c6cf8f8fdfcf8f.jpg',\n",
        "     'MaskTrainDataset/JPEGImages/0f37f662600081e1.jpg',\n",
        "     'MaskTrainDataset/JPEGImages/0000fdfcbc000660.jpg',\n",
        "     'MaskTrainDataset/JPEGImages/0ff99100498989cf.jpg',\n",
        "     'MaskTrainDataset/JPEGImages/00000c3e3e3e3c3e.jpg',\n",
        "     'MaskTrainDataset/JPEGImages/0000d8fe1f09bfff.jpg',\n",
        "     'MaskTrainDataset/JPEGImages/0f3f7f3720f0c000.jpg',\n",
        "     'MaskTrainDataset/JPEGImages/1b1bdfdac9c80102.jpg',\n",
        "     'MaskTrainDataset/JPEGImages/0fbf2f2c39b0f0f0.jpg',\n",
        "     'MaskTrainDataset/JPEGImages/00000000046e677f.jpg',\n",
        "     'MaskTrainDataset/JPEGImages/000000080e1e3e3e.jpg']\n",
        "print(IMAGE_PATHS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1d3_xLn99Bn4"
      },
      "source": [
        "#load the saved model\n",
        "\n",
        "import keras\n",
        "\n",
        "# serialize the model to disk\n",
        "print(\"[INFO] saving mask detector model...\")\n",
        "\n",
        "\n",
        "saved_model_path = \"Model\"\n",
        "\n",
        "\n",
        "#tf.saved_model.save(model, saved_model_path)\n",
        "model.save(saved_model_path)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjW-UZC8Hhvc"
      },
      "source": [
        "import tensorflow as tf\n",
        "#print(dt_string)\n",
        "model = keras.models.load_model(\"Model/\"+dt_string + \".h5\")\n",
        "detect_fn=tf.saved_model.load(\"Model\")\n",
        "#detect_fn = keras.models.load_model(\"Model/mask_detector_Adam_2020_12_25_15_34_55.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DASXgQ8gsJkx"
      },
      "source": [
        "\"\"\"\n",
        "for image_path in IMAGE_PATHS:\n",
        "\n",
        "    print('Running inference for {}... '.format(image_path), end='')\n",
        "\n",
        "    image_np = load_image_into_numpy_array(image_path)\n",
        "\n",
        "    # Things to try:\n",
        "    # Flip horizontally\n",
        "    # image_np = np.fliplr(image_np).copy()\n",
        "\n",
        "    # Convert image to grayscale\n",
        "    # image_np = np.tile(\n",
        "    #     np.mean(image_np, 2, keepdims=True), (1, 1, 3)).astype(np.uint8)\n",
        "\n",
        "    # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
        "    input_tensor = tf.convert_to_tensor(image_np)\n",
        "    # The model expects a batch of images, so add an axis with `tf.newaxis`.\n",
        "    input_tensor = input_tensor[tf.newaxis, ...]\n",
        "\n",
        "    #input_tensor = np.expand_dims(image_np, 0)\n",
        "    detections = detect_fn(input_tensor)\n",
        "\n",
        "    # All outputs are batches tensors.\n",
        "    # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
        "    # We're only interested in the first num_detections.\n",
        "    num_detections = int(detections.pop('num_detections'))\n",
        "    detections = {key: value[0, :num_detections].numpy()\n",
        "                   for key, value in detections.items()}\n",
        "    detections['num_detections'] = num_detections\n",
        "\n",
        "    # detection_classes should be ints.\n",
        "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
        "\n",
        "    image_np_with_detections = image_np.copy()\n",
        "\n",
        "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "          image_np_with_detections,\n",
        "          detections['detection_boxes'],\n",
        "          detections['detection_classes'],\n",
        "          detections['detection_scores'],\n",
        "          category_index,\n",
        "          use_normalized_coordinates=True,\n",
        "          max_boxes_to_draw=200,\n",
        "          min_score_thresh=.30,\n",
        "          agnostic_mode=False)\n",
        "\n",
        "    plt.figure()\n",
        "    plt.imshow(image_np_with_detections)\n",
        "    print('Done')\n",
        "plt.show()\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9rdTWfLsLFf"
      },
      "source": [
        "#load the saved model RAdam\n",
        "\"\"\"\n",
        "print('loading model...')\n",
        "opt = tfa.optimizers.RectifiedAdam(\n",
        "    lr=1e-3,\n",
        "    total_steps=10000,\n",
        "    warmup_proportion=0.1,\n",
        "    min_lr=1e-5,\n",
        ")\n",
        "\n",
        "ranger = tfa.optimizers.Lookahead(opt, sync_period=6, slow_step_size=0.5, name='Lookahead',)\n",
        "\n",
        "model = tf.keras.models.load_model('mask_detector_2020_12_19_07_20.h5', custom_objects={'Lookahead': ranger})\n",
        "\n",
        "print('model loaded')\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eF_dCAoWwn5"
      },
      "source": [
        "\n",
        "#train the saved model again \n",
        "print(\"[INFO] compiling model...\")\n",
        "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
        "\"\"\"\n",
        "opt = tfa.optimizers.RectifiedAdam(\n",
        "    lr=INIT_LR,\n",
        "    total_steps=5000,\n",
        "    warmup_proportion=0.1,\n",
        "    min_lr=INIT_LR\n",
        ")\n",
        "\"\"\"\n",
        "# Utilisation de l'optimizer dans un model (déjà configuré avant)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRfBDBxTrZ5o"
      },
      "source": [
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VG6gSS20WsTo"
      },
      "source": [
        "\n",
        "\n",
        "# train the head of the network\n",
        "print(\"[INFO] training head...\")\n",
        "\"\"\"\n",
        "H = model.fit(\n",
        "\taug.flow(trainX, trainY, batch_size=BS),\n",
        "\n",
        "\tvalidation_data=(testX, testY),\n",
        "\n",
        "\tepochs=EPOCHS\n",
        "  )\n",
        "\"\"\"\n",
        "H = model.fit(\n",
        "\taug.flow(trainX, trainY, batch_size=BS),\n",
        "\n",
        "\tvalidation_data=(testX, testY),\n",
        "\n",
        "\tepochs=EPOCHS,\n",
        "class_weight = {0:5 , 1:1, 2:10})\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtosBF9ZXNyo"
      },
      "source": [
        "#Evaluate the model again\n",
        "print(\"[INFO] evaluating network...\")\n",
        "predIdxs = model.predict(testX, batch_size=32)\n",
        "\n",
        "# for each image in the testing set we need to find the index of the\n",
        "# label with corresponding largest predicted probability\n",
        "predIdxs = np.argmax(predIdxs, axis=1)\n",
        "\n",
        "# show a nicely formatted classification report\n",
        "print(classification_report(testY.argmax(axis=1), predIdxs))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbz7lDVy9tMf"
      },
      "source": [
        "\n",
        "# plot the training loss and accuracy\n",
        "\n",
        "N = EPOCHS\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\n",
        "plt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
        "plt.title(\"Training Loss and Accuracy\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend(loc=\"lower left\")\n",
        "plt.savefig(\"Model/\"+ dt_string+\"_V1_1.png\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_F8gT6F9yZG"
      },
      "source": [
        "# serialize the model to disk\n",
        "print(\"[INFO] saving mask detector model...\")\n",
        "model.save(\"Model/\"+ dt_string+ \"_V1_1.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85_Cnuzoxp-u"
      },
      "source": [
        "\"\"\"\n",
        "for image_path in IMAGE_PATHS:\n",
        "\n",
        "    print('Running inference for {}... '.format(image_path), end='')\n",
        "\n",
        "    image_np = load_image_into_numpy_array(image_path)\n",
        "\n",
        "    # Things to try:\n",
        "    # Flip horizontally\n",
        "    image_np = np.fliplr(image_np).copy()\n",
        "\n",
        "    # Convert image to grayscale\n",
        "    image_np = np.tile(\n",
        "        np.mean(image_np, 2, keepdims=True), (1, 1, 3)).astype(np.uint8)\n",
        "\n",
        "    # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
        "    input_tensor = tf.convert_to_tensor(image_np)\n",
        "    # The model expects a batch of images, so add an axis with `tf.newaxis`.\n",
        "    input_tensor = input_tensor[tf.newaxis, ...]\n",
        "\n",
        "    input_tensor = np.expand_dims(image_np, 0)\n",
        "    detections = model(input_tensor)\n",
        "\n",
        "    # All outputs are batches tensors.\n",
        "    # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
        "    # We're only interested in the first num_detections.\n",
        "    num_detections = int(detections.pop('num_detections'))\n",
        "    detections = {key: value[0, :num_detections].numpy()\n",
        "                   for key, value in detections.items()}\n",
        "    detections['num_detections'] = num_detections\n",
        "\n",
        "    # detection_classes should be ints.\n",
        "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
        "\n",
        "    image_np_with_detections = image_np.copy()\n",
        "\n",
        "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "          image_np_with_detections,\n",
        "          detections['detection_boxes'],\n",
        "          detections['detection_classes'],\n",
        "          detections['detection_scores'],\n",
        "          category_index,\n",
        "          use_normalized_coordinates=True,\n",
        "          max_boxes_to_draw=200,\n",
        "          min_score_thresh=.30,\n",
        "          agnostic_mode=False)\n",
        "\n",
        "    plt.figure()\n",
        "    plt.imshow(image_np_with_detections)\n",
        "    print('Done')\n",
        "plt.show()\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}